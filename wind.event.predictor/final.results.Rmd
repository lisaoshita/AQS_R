---
title: "Model Results and Explanations"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# what to include

* objective + basic overview of the goals of this project 
* what packages need to be installed
* what was initially done (classification trees)
* include section for parameter tuning for each model 
* final model comparisons
* variable importance
* take-aways - points for future work

```{r, results='hide'}
# load packages
library(readr)
library(lubridate) # for working with dates
library(dplyr)
library(caret) 
library(AUC)
library(openair)
library(tree) # for classification tree at bottom
library(xgboost)
library(e1071) # for SVMs
```

# Overview

The objective of this project was to build a model to accurately predict wind event days based on meteorological data. For now, a wind event is defined as any day the 24-hour average PM10 concentration at CDF exceeds the state standard, i.e. 50ug/m3.

# Models explored:

* Random forest
* XGBoosts (extreme Gradient Boosted classification trees)
* Support vector machines (referred to as SVMs)
* regular classification trees

General process: For each model, parameter tuning was performed with 5-fold cross-validation on training sets to determine optimal parameter values. Models were then trained on the full training set using those parameters and then tested on the held-out test set. Classification accuracy and ROC/AUC metrics were assessed.

# Data and variable set up

This file uses data from S1 and CDF. Models were trained on data from 2011 - 2014 and tested on data from 2015 - 2017. The following code loads the data, partitions the data into training and test sets, and sets up the variables. 

```{r load data, echo=TRUE, results='hide'}
s1.cdf.data <- read_csv("H:/TECH/Lisa/R/apcd.r/wind.event.predictor/forLisa.csv",
                        col_types = list(date = "c", ws.cdf = "n", wd.cdf = "n",
                                         pm10.cdf = "n", pm10.oso = "n", wd.s1 = "n",
                                         ws.s1 = "n", year = "n")) # contains data from 2011 - 2017

s1.cdf.data <- s1.cdf.data %>%
  mutate(date = parse_date_time(date, "Ymd HMS"))

# contains cdf and S1 data up to 2014
cdf.master <- read_csv("H:/TECH/Lisa/R/apcd.r/wind.event.predictor/cdf.master.csv",
                       col_types = list(date = "c", ws = "n", wd = "n", pm25 = "n",
                                        pm10 = "n", u = "n", v = "n", year = "n", 
                                        precip = "n", s.rad = "n", a.temp = "n",
                                        rh = "n", dp = "n", s.temp = "n", height = "n",
                                        temp850 = "n", ws.max = "n", wd.max = "n",
                                        u.max = "n", v.max = "n", time = "n", dow = "n",
                                        u.s1 = "n", v.s1 = "n", u.max.s1 = "n", v.max.s1 = "n"))

cdf.master$date <- date(cdf.master$date)

# contains cdf and S1 data from 2014 - 2017
cdf.master2 <- read_csv("H:/TECH/Lisa/R/apcd.r/wind.event.predictor/cdf.master.update.csv",
                        col_types = list(date = "c", ws = "n", wd = "n", pm25 = "n", pm10 = "n",
                                        u = "n", v = "n", year = "n", precip = "n",
                                        s.rad = "n", a.temp = "n", rh = "n", dp = "n",
                                        s.temp = "n", height = "n", temp850 = "n", ws.max = "n",
                                        wd.max = "n", u.max = "n", v.max = "n", time = "n",
                                        dow = "n", u.s1 = "n", v.s1 = "n", u.max.s1 = "n",
                                        v.max.s1 = "n"))

cdf.master2$date <- date(cdf.master2$date)
```

```{r format training data, echo=TRUE, results='hide'}
# train on years before 2015
training <- s1.cdf.data %>%
  mutate(year = lubridate::year(date)) %>%
  mutate(date.only = lubridate::date(date)) %>%
  filter(year < 2015)

# =========================================================================================
# finding wd and ws values at CDF and S1 that correspond with high pm10 concentrations
# using openair package

# ====
# CDF 
# ====
cdf.training <- training %>%
  select(date, year, ws.cdf, wd.cdf, pm10.cdf)
colnames(cdf.training) <- c("date", "year", "ws", "wd", "pm10")

cdf.clust <- polarCluster(cdf.training, 
                          pollutant = "pm10",
                          x = "ws",
                          wd = "wd",
                          n.clusters = 2) # cluster 2 is high pm10 

cdf.clust$data %>%
  filter(cluster == 2) %>%
  summarize(min_wd = min(wd),
            max_wd = max(wd),
            min_ws = min(ws),
            max_ws = max(ws)) # CRITERIA: wd between 288 - 320, ws between 9.2 - 20.7

# ===
# S1 
# ===
s1.training <- training %>%
  select(date, year, wd.s1, ws.s1, pm10.cdf)
colnames(s1.training) <- c("date", "year", "wd", "ws", "pm10")

s1.clust <- polarCluster(s1.training,
                         pollutant = "pm10",
                         x = "ws",
                         wd = "wd",
                         n.clusters = 2)

s1.clust$data %>%
  filter(cluster == 2) %>%
  summarize(min_wd = min(wd),
            max_wd = max(wd),
            min_ws = min(ws),
            max_ws = max(ws)) # CRITERIA: high pm10 if wd between 281 - 306, ws between 8.88 - 16.11

# =========================================================================================

# WD and WS variable set up 
train1 <- training %>%
  group_by(date.only) %>%
  summarize(max.ws.cdf = max(ws.cdf, na.rm = TRUE), # maximum WS & WD at CDF and S1
            max.wd.cdf = max(wd.cdf, na.rm = TRUE),
            max.ws.s1 = max(ws.s1, na.rm = TRUE),
            max.wd.s1 = max(wd.s1, na.rm = TRUE),
            hour.max.wd.s1 = ifelse(length(which.max(wd.s1)) == 0, NA, which.max(wd.s1) - 1), # hour of the day that WS and WD were at maximum
            hour.max.ws.s1 = ifelse(length(which.max(ws.s1)) == 0, NA, which.max(ws.s1) - 1),
            hour.max.wd.cdf = ifelse(length(which.max(wd.cdf)) == 0, NA, which.max(wd.cdf) - 1),
            hour.max.ws.cdf = ifelse(length(which.max(ws.cdf)) == 0, NA, which.max(ws.cdf) - 1),
            ws.in.range.cdf = sum((ws.cdf > 9), na.rm = TRUE), # number of times that WS and WD fell within the range corresponding to high pm10 averages
            wd.in.range.cdf = sum((wd.cdf > 288) & (wd.cdf < 320), na.rm = TRUE),
            wd.in.range.s1 = sum((wd.s1 > 281) & (wd.s1 < 306), na.rm = TRUE),
            ws.in.range.s1 = sum((ws.s1 > 8), na.rm = TRUE)) %>%
  mutate(max.ws.cdf = ifelse(max.ws.cdf == -Inf, NA, max.ws.cdf)) %>% # changing "-Inf" values in max variables to NA
  mutate(max.wd.cdf = ifelse(max.wd.cdf == -Inf, NA, max.wd.cdf)) %>%
  mutate(max.ws.s1 = ifelse(max.ws.s1 == -Inf, NA, max.ws.s1)) %>%
  mutate(max.wd.s1 = ifelse(max.wd.s1 == -Inf, NA, max.wd.s1))

# =========================================================================================

# computing pm10 avg 24 hr concentration
pm10.averages <- training %>%
  group_by(date.only) %>%
  summarize(pm10.ave = mean(pm10.cdf, na.rm = TRUE)) %>%
  mutate(did.exceed = ifelse(pm10.ave >= 50, "yes", "no"))

colnames(train1)[1] <- "date"

# merge train1 with other columns in cdf.master
train1 <- train1 %>%
  mutate(did.exceed = pm10.averages$did.exceed) %>% # add did.exceed response variable
  left_join(cdf.master, by = "date") %>% 
  mutate(month = month(date)) %>% # create month and day.of.month variables
  mutate(day.of.month = day(date)) %>%
  select(did.exceed, ws.in.range.cdf, wd.in.range.cdf, wd.in.range.s1, # retain only a subset of the variables for the model
         ws.in.range.s1, max.ws.cdf, max.wd.cdf, max.ws.s1, max.wd.s1,
         hour.max.wd.s1, hour.max.ws.s1, hour.max.wd.cdf, hour.max.wd.cdf, 
         precip, s.rad, a.temp, rh, dp, s.temp, height, temp850, month, day.of.month)

# =========================================================================================

# examining missing data w/ missingness map 
# Amelia::missmap(train1) # only 3% of the training data is missing - ok to omit these rows
train1 <- na.omit(train1) 

train1$did.exceed <- as.factor(train1$did.exceed)
```

```{r format test data, echo=TRUE, results='hide'}
# test on years after 2015
testing <- s1.cdf.data %>%
  mutate(year = lubridate::year(date)) %>%
  mutate(date.only = lubridate::date(date)) %>%
  filter(year >= 2015)

# variable set up
test <- testing %>%
  group_by(date.only) %>%
  summarize(max.ws.cdf = max(ws.cdf, na.rm = TRUE),
            max.wd.cdf = max(wd.cdf, na.rm = TRUE),
            max.ws.s1 = max(ws.s1, na.rm = TRUE),
            max.wd.s1 = max(wd.s1, na.rm = TRUE),
            hour.max.wd.s1 = ifelse(length(which.max(wd.s1)) == 0, NA, which.max(wd.s1) - 1),
            hour.max.ws.s1 = ifelse(length(which.max(ws.s1)) == 0, NA, which.max(ws.s1) - 1),
            hour.max.wd.cdf = ifelse(length(which.max(wd.cdf)) == 0, NA, which.max(wd.cdf) - 1),
            hour.max.ws.cdf = ifelse(length(which.max(ws.cdf)) == 0, NA, which.max(ws.cdf) - 1),
            ws.in.range.cdf = sum((ws.cdf > 9), na.rm = TRUE),
            wd.in.range.cdf = sum((wd.cdf > 288) & (wd.cdf < 320), na.rm = TRUE),
            wd.in.range.s1 = sum((wd.s1 > 281) & (wd.s1 < 306), na.rm = TRUE),
            ws.in.range.s1 = sum((ws.s1 > 8), na.rm = TRUE)) %>%
  mutate(max.ws.cdf = ifelse(max.ws.cdf == -Inf, NA, max.ws.cdf)) %>%
  mutate(max.wd.cdf = ifelse(max.wd.cdf == -Inf, NA, max.wd.cdf)) %>%
  mutate(max.ws.s1 = ifelse(max.ws.s1 == -Inf, NA, max.ws.s1)) %>%
  mutate(max.wd.s1 = ifelse(max.wd.s1 == -Inf, NA, max.wd.s1))

colnames(test)[1] <- "date"

# computing 24 hour average pm10 concentration
pm10.averages.test <- testing %>%
  group_by(date.only) %>%
  summarize(pm10.ave = mean(pm10.cdf, na.rm = TRUE)) %>%
  mutate(did.exceed = ifelse(pm10.ave >= 50, "yes", "no"))

# merge test with other columns in cdf.master2
test <- test %>%
  mutate(did.exceed = pm10.averages.test$did.exceed) %>%
  left_join(cdf.master2, by = "date") %>%
  mutate(month = month(date)) %>%
  mutate(day.of.month = day(date)) %>%
  select(did.exceed, ws.in.range.cdf, wd.in.range.cdf, wd.in.range.s1, 
         ws.in.range.s1, max.ws.cdf, max.wd.cdf, max.ws.s1, max.wd.s1,
         hour.max.wd.s1, hour.max.ws.s1, hour.max.wd.cdf, hour.max.wd.cdf, 
         precip, s.rad, a.temp, rh, dp, s.temp, height, temp850, month, day.of.month)

# assess rows with missing data
# Amelia::missmap(test) # only 2% of the training data is missing - ok to omit these rows
test <- na.omit(test) 

test$did.exceed <- as.factor(test$did.exceed)
```


# Random forest

The following is an example of the process of parameter tuning. `grid` contains all combinations of parameters to assess. `mtry` is the number of predictors to randomly sample at each split. The default for this parameter is the square root of the number of predictors in the data. `splitrule` determines how splits will be decided. `min.node.size` defines the minimum number of observations that can be within a terminal node. 

`tune.control` specifies how to perform the tuning process (5-fold cross-validation) and sets various other options (e.g. `verboseIter = FALSE` indicates that each iteration should not be printed to the console). 

```{r}
# parameter tuning set up
grid <- expand.grid(.mtry = c(round(sqrt(ncol(train1))), 
                              8, 10, 15),
                    .splitrule = "gini",
                    .min.node.size = c(5, 10, 20))

grid

tune.control <- trainControl(method = "cv", 
                             number = 5,
                             verboseIter = FALSE,
                             classProbs = TRUE,
                             summaryFunction = twoClassSummary) # twoClassSummary is needed for ROC/AUC metrics
```

Parameter tuning is performed with the `train()` function from the caret package. Since the number of trees to grow is not a parameter than can be tuned by including it in the grid, tuning was performed three times to explore different values of `num.trees`.

```{r}
set.seed(1)

# tuning on 500 trees
start.tune.500 <- Sys.time()
rf.tuning.500 <- train(did.exceed ~ ., 
                       data = train1, 
                       method = "ranger", # fast implementation of a random forest: ranger, e1071 need to be installed
                       tuneGrid = grid, 
                       num.trees = 500,
                       trControl = tune.control,
                       importance = "impurity",
                       metric = "ROC")
end.tune.500 <- Sys.time() # 19 seconds

# tuning on 1000 trees
start.tune.1000 <- Sys.time()
rf.tuning.1000 <- train(did.exceed ~ ., 
                        data = train1, 
                        method = "ranger", 
                        tuneGrid = grid, 
                        num.trees = 1000,
                        trControl = tune.control,
                        importance = "impurity",
                        metric = "ROC")
end.tune.1000 <- Sys.time() # 1.40 minutes

# tuning on 1500 trees
start.tune.1500 <- Sys.time()
rf.tuning.1500 <- train(did.exceed ~ ., 
                        data = train1, 
                        method = "ranger",
                        tuneGrid = grid, 
                        num.trees = 1500,
                        trControl = tune.control,
                        importance = "impurity",
                        metric = "ROC")
end.tune.1500 <- Sys.time() # 1.65 minutes


# parameter tuning results
rf.tuning.500$results # ROC: 0.9468062, Sens = 0.9687824, Spec = 0.7045118 --- mtry = 8, min.node.size = 5
rf.tuning.500$bestTune

rf.tuning.1000$results # ROC: 0.9506774, Sens = 0.9698187, spec = 0.6937374 --- mtry = 5, min.node.size = 5
rf.tuning.1000$bestTune

rf.tuning.1500$results # ROC: 0.9526248, Sens = 0.9729383, Spec = 0.7154209 --- mtry = 5, min.node.size = 5
rf.tuning.1500$bestTune

plot(rf.tuning.1500)

# assessing variable importance
varImp(rf.tuning.1500)
plot(varImp(rf.tuning.1500))
```

The parameters that lead to the best performance were: ... with 1,500 trees grown. 



