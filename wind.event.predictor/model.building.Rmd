---
title: "Wind Event Predictor"
author: "Lisa Oshita"
date: "October 3, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, results='hide'}
# load packages
library(readr)
library(lubridate) # for working with dates
library(dplyr)
library(caret) 
library(AUC)
library(openair)
```

# Objective

Build a model to predict wind event days, based on meteorological data. A wind event is defined as any day when the 24-hour average PM10 concentration at CDF exceeds the state standard, i.e. 50 ug/m3. 

# Load data

```{r}
s1.data <- read_csv("H:/TECH/Lisa/R/apcd.r/wind.event.predictor/forLisa.csv",
                    col_types = list(date = "c",
                                     ws.cdf = "n",
                                     wd.cdf = "n",
                                     pm10.cdf = "n",
                                     pm10.oso = "n",
                                     wd.s1 = "n",
                                     ws.s1 = "n",
                                     year = "n")) # contains data from 2011 - 2017

s1.data <- s1.data %>%
  mutate(date = parse_date_time(date, "Ymd HMS"))

cdf.master <- read_csv("H:/TECH/Lisa/R/apcd.r/wind.event.predictor/cdf.master.csv",
                       col_types = list(date = "c",
                                        ws = "n",
                                        wd = "n",
                                        pm25 = "n",
                                        pm10 = "n",
                                        u = "n",
                                        v = "n", 
                                        year = "n",
                                        precip = "n",
                                        s.rad = "n",
                                        a.temp = "n",
                                        rh = "n",
                                        dp = "n",
                                        s.temp = "n",
                                        height = "n",
                                        temp850 = "n",
                                        ws.max = "n",
                                        wd.max = "n",
                                        u.max = "n",
                                        v.max = "n",
                                        time = "n",
                                        dow = "n",
                                        u.s1 = "n",
                                        v.s1 = "n",
                                        u.max.s1 = "n",
                                        v.max.s1 = "n"))

cdf.master$date <- date(cdf.master$date)
```

```{r}
# formatting s1.data
s1.data <- s1.data %>%
  mutate(date1 = lubridate::date(date)) %>%
  mutate(hour = lubridate::hour(date))

# converting data frame to wide format
# single date for each row, hours in the columns
d <- s1.data[s1.data$hour==0, c(9, 2, 3)]
names(d) <- c("date1", paste(names(d)[-1], 0, sep="."))

for(i in 1:23){
  dd <- s1.data[s1.data$hour==i, c(2, 3, 6, 7)]
  names(dd) <- paste(names(dd), i, sep=".")
  d <- cbind(d,dd)
}

rm(dd, i)

# 24 hour pm10 averages + creating binary did.exceed variable
pm10.averages <- s1.data %>%
  group_by(date1) %>%
  summarize(pm10.ave = mean(pm10.cdf, na.rm = TRUE)) %>%
  mutate(did.exceed = ifelse(pm10.ave >= 50, "yes", "no")) %>%
  select(-date1)


d <- cbind(d, pm10.averages)

rm(pm10.averages)

# only using wd and ws at CDF for now, 5% of wd and ws for S1 are missing (think of ways for dealing with this - include variable for is.missing?) 

colnames(d)[1] <- "date"

# joining cdf.master
# cdf.master.subset <- cdf.master %>%
#   select(date, precip, s.rad, a.temp, rh, s.temp)
# 
# d <- d %>%
#   left_join(cdf.master.subset, by = "date")
# precip, s.rad, a.temp, rh, s.temp all have ~50% missing values
# remove these for now


# creating month variable + removing variables not to be included in the model
d <- d %>%
  mutate(month = lubridate::month(date)) %>%
  select(-pm10.ave)


# partition into training and test sets
# train on all years before 2015, test on 2015, 2016
train <- d %>% 
  filter(lubridate::year(date) < 2015) %>%
  select(-date) %>%
  mutate(did.exceed = as.factor(did.exceed))

test.x <- d %>% 
  filter(lubridate::year(date) >= 2015) %>%
  select(-date) %>%
  mutate(did.exceed = as.factor(did.exceed))
test.x <- na.omit(test.x) # remove rows with missing values
test.y <- test.x$did.exceed

test.x <- test.x %>% select(-did.exceed)
```

```{r}
training <- s1.data %>%
  filter(lubridate::year(date) < 2015)

cdf.training <- training %>%
  select(date, year, ws.cdf, wd.cdf, pm10.cdf)
colnames(cdf.training) <- c("date", "year", "ws", "wd", "pm10")

s1.training <- training %>%
  select(date, year, wd.s1, ws.s1, pm10.cdf) %>%
  mutate(wd.s1 = as.integer(wd.s1)) %>%
  mutate(ws.s1 = as.numeric(ws.s1))
colnames(s1.training) <- c("date", "year", "wd", "ws", "pm10")

polarPlot(cdf.training, 
          pollutant = "pm10",
          x = "ws",
          wd = "wd")

cdf.clust <- polarCluster(cdf.training, 
                          pollutant = "pm10",
                          x = "ws",
                          wd = "wd",
                          n.clusters = 2) # cluster 2 is high pm10 

cdf.clust$data %>%
  filter(cluster == 2) %>%
  summarize(min_wd = min(wd),
            max_wd = max(wd),
            min_ws = min(ws),
            max_ws = max(ws)) # criteria: wd between 288 - 320, ws between 9.2 - 20.7


s1.clust <- polarCluster(s1.training,
                         pollutant = "pm10",
                         x = "ws",
                         wd = "wd",
                         n.clusters = 2)

s1.clust$data %>%
  filter(cluster == 2) %>%
  summarize(min_wd = min(wd),
            max_wd = max(wd),
            min_ws = min(ws),
            max_ws = max(ws)) # criteria: wd between 281 - 306, ws between 8.88 - 16.11

# creating variables indicating if wd or ws falls within these ranges 

# group by day, count the number of times wd + ws fall within the ranges, time of day that they do fall in the range?  (or maybe time of day that had the most extreme values) 

train1 <- training %>%
  mutate(date.only = lubridate::date(date)) %>%
  group_by(date.only) %>%
  summarize(ws.in.range.cdf = sum((ws.cdf > 9) & (ws.cdf < 21), na.rm = T),
            wd.in.range.cdf = sum((wd.cdf > 288) & (wd.cdf < 320), na.rm = T),
            wd.in.range.s1 = sum((wd.s1 > 281) & (wd.s1 < 306), na.rm = T),
            ws.in.range.s1 = sum((ws.s1 > 8) & (ws.s1 < 17), na.rm = T))


# adding pm10 variable
pm10.averages <- training %>%
  mutate(date.only = lubridate::date(date)) %>%
  group_by(date.only) %>%
  summarize(pm10.ave = mean(pm10.cdf, na.rm = TRUE)) %>%
  mutate(did.exceed = ifelse(pm10.ave >= 50, "yes", "no"))

# merge train1 with other columns in cdf.master
head(cdf.master)
colnames(train1)[1] <- "date"

train1$did.exceed = pm10.averages$did.exceed


train1 <- train1 %>%
  left_join(cdf.master, by = "date") %>%
  select(date, ws.in.range.cdf, wd.in.range.cdf, wd.in.range.s1, 
         ws.in.range.s1, did.exceed, precip, s.rad, a.temp, rh, s.temp) %>%
  mutate(month = month(date))

train1 <- na.omit(train1)
```


```{r}

```


# Examining the response variable 

```{r}
prop.table(table(d$did.exceed))

prop.table(table(train$did.exceed))
# some class imbalance is present
```

```{r}
# random forest won't work with missing values 
# removing rows that contain NAs (only 82 rows contained NAs)
train <- na.omit(train) 

sqrt(ncol(train))
```

# Random Forest parameter tuning

```{r}
grid <- expand.grid(.mtry = c(5, round(sqrt(ncol(train))), 
                              20, 30),
                    .splitrule = "gini",
                    .min.node.size = c(5, 10, 20))

tune.control <- trainControl(method = "cv", 
                             number = 5,
                             verboseIter = TRUE,
                             classProbs = TRUE)

set.seed(1)
ncol(train)
# tuning on 500 trees
start.tune.500 <- Sys.time()
rf.tuning500 <- train(did.exceed ~ ., 
                   data = train, 
                   method = "ranger", # fast implementation of a random forest: ranger, e1071 need to be installed
                   tuneGrid = grid, 
                   num.trees = 500,
                   trControl = tune.control)
end.tune.500 <- Sys.time() # 45 seconds

end.tune.500 - start.tune.500 # 22.87068 mins
# tuning on 1000 trees
start.tune.1000 <- Sys.time()
rf.tuning1000 <- train(did.exceed ~ ., 
                   data = train, 
                   method = "ranger", 
                   tuneGrid = grid, 
                   num.trees = 1000,
                   trControl = tune.control)
end.tune.1000 <- Sys.time() # 1.40 minutes

# tuning on 1500 trees
start.tune.1500 <- Sys.time()
rf.tuning.1500 <- train(did.exceed ~ ., 
                   data = train, 
                   method = "ranger",
                   tuneGrid = grid, 
                   num.trees = 1500,
                   trControl = tune.control)
end.tune.1500 <- Sys.time() # 1.65 minutes


# parameter tuning results
plot(rf.tuning500) 
rf.tuning500
rf.tuning500$bestTune # accuracy: 0.8948349, mtry = 15, min.node.size = 5


plot(rf.tuning1000)
rf.tuning1000
rf.tuning1000$bestTune # accuracy: 0.8949005, mtry = 7, min.node.size = 10


plot(rf.tuning.1500)
rf.tuning.1500
rf.tuning.1500$bestTune # accuracy: 0.8941238, mtry = 15, min.node.size = 20


## really is no difference in accuracy among these models
```

# Fitting model to the full training set

```{r}
final.grid <- data.frame(.mtry = 7,
                         .splitrule = "gini",
                         .min.node.size = 10)

final.control <- trainControl(method = "none",
                              verboseIter = TRUE,
                              classProbs = TRUE)
  
start.fit <- Sys.time()
rf.fit <- train(did.exceed ~ ., 
                data = train,
                method = "ranger",
                tuneGrid = final.grid,
                trControl = final.control,
                num.trees = 1000,
                importance = "impurity")
end.fit <- Sys.time() # 1.4 seconds

# compute predictions
rf.preds <- predict(rf.fit, newdata = test.x, type = "prob")

rf.preds <- rf.preds %>%
  mutate(prediction = ifelse(yes > 0.50, "yes", "no")) %>%
  mutate(actual = test.y)

# classification accuracy
mean(rf.preds$actual == rf.preds$prediction) # 87% accuracy

# ROC, AUC
roc.metric <- roc(predictions = rf.preds$yes,
                  labels = as.factor(ifelse(as.character(test.y) == "yes", 1, 0)))
auc.metric <- auc(roc.metric)

plot(roc.metric, main = paste("AUC:", auc.metric))
# sensitivity: true positive rate - ability of the model to correctly identify wind event days
# specificity: true negative rate - ability of the model to correctly identify non-wind event days

# assessing variable importance
# this plot shows 
plot(varImp(rf.fit))
varImp(rf.fit)
```

# Results of this round of parameter tuning

The random forest trained on wind speed and direction at CDF for different hours of the day as well as month + parameter tuned did not seem to result in an improvement in accuracy 

* correlation between wind direction variables throughout the day 
* correlation between wind speed variables throughout the day 

```{r}
library(ggplot2)

ggplot(s1.data, aes(x = ws.cdf)) + 
  geom_histogram()

# instead only keep track of the number of times wind speed was greater than 5? 
# and how many times it was > 5, the hours of the day it was > 5

# have a single variable determining if wind direction is pointing in the "right" way

ggplot(s1.data, aes(x = wd.cdf)) + 
  geom_histogram() # bimodal? 
```


```{r}
# looking at s1 variables and missing values

delete <- s1.data %>%
  filter(!is.na(ws.s1)) %>%
group_by(date1) 
```








